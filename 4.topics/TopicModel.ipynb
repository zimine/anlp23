{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll explore topic modeling to discover broad themes in a collection of movie summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mingyu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import operator\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_stopwords(filename):\n",
    "    stopwords={}\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            stopwords[line.rstrip()]=1\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're running topic modeling on texts with lots of names, we'll add the Jockers list of stopwords (which includes character names) to our stoplist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = {k:1 for k in stopwords.words('english')}\n",
    "stop_words.update(read_stopwords(\"../data/jockers.stopwords\"))\n",
    "stop_words[\"'s\"]=1\n",
    "stop_words=list(stop_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter(word, stopwords):\n",
    "    \n",
    "    \"\"\" Function to exclude words from a text \"\"\"\n",
    "    \n",
    "    # no stopwords\n",
    "    if word in stopwords:\n",
    "        return False\n",
    "    \n",
    "    # has to contain at least one letter\n",
    "    if re.search(\"[A-Za-z]\", word) is not None:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_docs(plotFile, metadataFile, stopwords):\n",
    "    \n",
    "    names={}\n",
    "    box={}\n",
    "    \n",
    "    with open(metadataFile, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            idd=cols[0]\n",
    "            name=cols[2]\n",
    "            boxoffice=cols[4]\n",
    "            if len(boxoffice) != 0:\n",
    "                box[idd]=int(boxoffice)\n",
    "                names[idd]=name\n",
    "    \n",
    "    n=5000\n",
    "    target_movies={}\n",
    "\n",
    "\n",
    "    sorted_box = sorted(box.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for k, v in sorted_box[:n]:\n",
    "        target_movies[k]=names[k]\n",
    "    \n",
    "    docs=[]\n",
    "    names=[]\n",
    "   \n",
    "    with open(plotFile, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            idd=cols[0]\n",
    "            text=cols[1]\n",
    "            \n",
    "            if idd in target_movies:\n",
    "                tokens=nltk.word_tokenize(text.lower())\n",
    "                tokens=[x for x in tokens if filter(x, stopwords)]\n",
    "                docs.append(tokens)\n",
    "                name=target_movies[idd]\n",
    "                names.append(name)\n",
    "    return docs, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in summaries of the 5,000 movies with the highest box office revenues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadataFile=\"../data/movie.metadata.tsv\"\n",
    "plotFile=\"../data/plot_summaries.txt\"\n",
    "data, doc_names=read_docs(plotFile, metadataFile, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4778"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the movie summaries into a bag-of-words representation using gensim's [corpora.dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create vocab from data; restrict vocab to only the top 10K terms that show up in at least 5 documents \n",
    "# and no more than 50% of all documents\n",
    "\n",
    "dictionary = corpora.Dictionary(data)\n",
    "dictionary.filter_extremes(no_below=5, no_above=.5, keep_n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace dataset with numeric ids words in vocab (and exclude all other words)\n",
    "# bag-of-words format: token ids and token counts\n",
    "corpus = [dictionary.doc2bow(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4778"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17, 1),\n",
       " (32, 1),\n",
       " (36, 1),\n",
       " (38, 1),\n",
       " (42, 2),\n",
       " (50, 1),\n",
       " (55, 1),\n",
       " (57, 1),\n",
       " (59, 1),\n",
       " (76, 1),\n",
       " (80, 2),\n",
       " (86, 1),\n",
       " (97, 1),\n",
       " (98, 1),\n",
       " (99, 1),\n",
       " (100, 5),\n",
       " (121, 9),\n",
       " (124, 3),\n",
       " (131, 1),\n",
       " (143, 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[2][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_topics=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run a topic model on this data using gensim's built-in LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=num_topics, \n",
    "                                           passes=10,\n",
    "                                           alpha='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a sense of what the topics are by printing the top 10 words with highest $P(word \\mid topic)$ for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0:\twill war men\n",
      "topic 1:\tpolice car killed\n",
      "topic 2:\thouse michael tells\n",
      "topic 3:\tfind off through\n",
      "topic 4:\tnew will father\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_topics):\n",
    "    print(\"topic %s:\\t%s\" % (i, ' '.join([term for term, freq in lda_model.show_topic(i, topn=3)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0:\twill war men ; this army ' father during all\n",
      "topic 1:\tpolice car killed been man kill money frank had ;\n",
      "topic 2:\thouse michael tells home father night goes finds david room\n",
      "topic 3:\tfind off through can escape earth its dr. ; will\n",
      "topic 4:\tnew will father love film this tells life time mother\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_topics):\n",
    "    print(\"topic %s:\\t%s\" % (i, ' '.join([term for term, freq in lda_model.show_topic(i, topn=10)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of understanding topics is to print out the documents that have the highest topic representation -- i.e., for a given topic $k$, the documents with highest $P(topic=k | document)$.  How much do the documents listed here align with your understanding of the topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('david', 0.023339266),\n",
       " ('jimmy', 0.013298975),\n",
       " ('band', 0.013000627),\n",
       " ('bobby', 0.012748592),\n",
       " ('terry', 0.010856751),\n",
       " ('amy', 0.007921143),\n",
       " ('show', 0.0073583373),\n",
       " ('emma', 0.0071322545),\n",
       " ('[', 0.0071055167),\n",
       " ('club', 0.00558657)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.show_topic(0, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.3034238),\n",
       " (7, 0.11577231),\n",
       " (8, 0.06235964),\n",
       " (12, 0.17282276),\n",
       " (13, 0.2732274),\n",
       " (17, 0.07075198)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_document_topics(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will war men ; this army ' father during all\n",
      "\n",
      "0\t0.998\tThe Last Legion\n",
      "0\t0.998\tKingdom of Heaven\n",
      "0\t0.998\tThe Bridge on the River Kwai\n",
      "0\t0.998\tCenturion\n",
      "0\t0.998\tWelcome to Dongmakgol\n",
      "\n",
      "police car killed been man kill money frank had ;\n",
      "\n",
      "1\t0.999\tThe Taking of Pelham 1 2 3\n",
      "1\t0.999\tExit Wounds\n",
      "1\t0.998\tRansom\n",
      "1\t0.998\tU.S. Marshals\n",
      "1\t0.998\tStreet Kings\n",
      "\n",
      "house michael tells home father night goes finds david room\n",
      "\n",
      "2\t0.999\tDeck the Halls\n",
      "2\t0.999\tPsycho II\n",
      "2\t0.999\tThe Rage: Carrie 2\n",
      "2\t0.999\tShutter\n",
      "2\t0.998\tThe Ring\n",
      "\n",
      "find off through can escape earth its dr. ; will\n",
      "\n",
      "3\t0.998\tSmall Soldiers\n",
      "3\t0.998\t9\n",
      "3\t0.998\tThe Thing\n",
      "3\t0.998\tAlien\n",
      "3\t0.998\tThe Iron Giant\n",
      "\n",
      "new will father love film this tells life time mother\n",
      "\n",
      "4\t0.999\tNine\n",
      "4\t0.999\tDiary of a Wimpy Kid: Dog Days\n",
      "4\t0.999\tBridesmaids\n",
      "4\t0.999\tThe Help\n",
      "4\t0.999\tThe Way Home\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_model=lda_model \n",
    "\n",
    "topic_docs=[]\n",
    "for i in range(num_topics):\n",
    "    topic_docs.append({})\n",
    "for doc_id in range(len(corpus)):\n",
    "    doc_topics=topic_model.get_document_topics(corpus[doc_id])\n",
    "    for topic_num, topic_prob in doc_topics:\n",
    "        topic_docs[topic_num][doc_id]=topic_prob\n",
    "\n",
    "for i in range(num_topics):\n",
    "    print(\"%s\\n\" % ' '.join([term for term, freq in topic_model.show_topic(i, topn=10)]))\n",
    "    sorted_x = sorted(topic_docs[i].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for k, v in sorted_x[:5]:\n",
    "        print(\"%s\\t%.3f\\t%s\" % (i,v,doc_names[k]))\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steve elizabeth linda simon graham buddy vampire richie jonathan sophie\n",
      "\n",
      "0\t0.809\tBats\n",
      "0\t0.625\tZathura\n",
      "0\t0.620\tCirque du Freak: The Vampire's Assistant\n",
      "0\t0.595\tDeck the Halls\n",
      "0\t0.472\tHollow Man\n",
      "\n",
      "michael sarah matt adam kyle beth roger april jesus sara\n",
      "\n",
      "1\t0.629\tThe Passion of the Christ\n",
      "1\t0.601\tHe Got Game\n",
      "1\t0.563\tClick\n",
      "1\t0.541\tJesus Christ Superstar\n",
      "1\t0.517\tA Good Day to Have an Affair\n",
      "\n",
      "ray chris johnny team alien gordon through nuclear dr. earth\n",
      "\n",
      "2\t0.894\tAlien: Resurrection\n",
      "2\t0.781\tBeneath the Planet of the Apes\n",
      "2\t0.778\tQueen of Blood\n",
      "2\t0.686\tFirefox\n",
      "2\t0.668\tThe Core\n",
      "\n",
      "school tells new will go does love get day this\n",
      "\n",
      "3\t0.958\tA Chorus Line\n",
      "3\t0.955\tBooty Call\n",
      "3\t0.949\tMy Wife Got Married\n",
      "3\t0.934\tEasy A\n",
      "3\t0.927\tFresh Horses\n",
      "\n",
      "money james will father don santa christmas time lee jerry\n",
      "\n",
      "4\t0.837\tRollover\n",
      "4\t0.757\tWall Street: Money Never Sleeps\n",
      "4\t0.735\tTwo If by Sea\n",
      "4\t0.716\tEye for an Eye\n",
      "4\t0.695\tSanta Claus: The Movie\n",
      "\n",
      "mary peter jane larry brian ash william jean catherine zack\n",
      "\n",
      "5\t0.729\tNight at the Museum: Battle of the Smithsonian\n",
      "5\t0.607\tThe Muppets\n",
      "5\t0.528\tGosford Park\n",
      "5\t0.512\tThe Amazing Spider-Man\n",
      "5\t0.503\tReturn to Never Land\n",
      "\n",
      "dr. carter amy karen kane maria owen nathan cross easy\n",
      "\n",
      "6\t0.384\tAustin Powers: Goldmember\n",
      "6\t0.339\tDevil in a Blue Dress\n",
      "6\t0.321\tThe Bear\n",
      "6\t0.320\tAustin Powers: The Spy Who Shagged Me\n",
      "6\t0.313\tDr. Dolittle 2\n",
      "\n",
      "police killed kill agent joe men been case bond had\n",
      "\n",
      "7\t0.828\tQuantum of Solace\n",
      "7\t0.814\tMaximum Risk\n",
      "7\t0.806\tNever Say Never Again\n",
      "7\t0.796\tThe Amateur\n",
      "7\t0.795\tRighteous Ties\n",
      "\n",
      "nick danny eddie } { vincent emily money police sebastian\n",
      "\n",
      "8\t0.604\tThe Devil's Game\n",
      "8\t0.585\tHaunters\n",
      "8\t0.582\tMenace II Society\n",
      "8\t0.557\tPolice Academy 2: Their First Assignment\n",
      "8\t0.545\tOcean's Twelve\n",
      "\n",
      "charlie war army soldiers men general during american japanese orders\n",
      "\n",
      "9\t0.900\tThe Thin Red Line\n",
      "9\t0.894\tFlyboys\n",
      "9\t0.871\tWindtalkers\n",
      "9\t0.824\tInto the Fire\n",
      "9\t0.822\tThe Bridge on the River Kwai\n",
      "\n",
      "jack billy island boat ship off water other captain group\n",
      "\n",
      "10\t0.875\tKing Kong\n",
      "10\t0.700\tKing Kong\n",
      "10\t0.689\tThe Perfect Storm\n",
      "10\t0.679\tThe Day After Tomorrow\n",
      "10\t0.677\tOrca\n",
      "\n",
      "house finds room find body police through car night goes\n",
      "\n",
      "11\t0.898\tParanormal Activity\n",
      "11\t0.882\tThe House on Sorority Row\n",
      "11\t0.875\tSorority Row\n",
      "11\t0.870\tThe Strangers\n",
      "11\t0.859\tThe Blair Witch Project\n",
      "\n",
      "team game jake roy win tony race play fight coach\n",
      "\n",
      "12\t0.911\tRudo y Cursi\n",
      "12\t0.686\tBad News Bears\n",
      "12\t0.678\tInvincible\n",
      "12\t0.651\tTazza: The High Rollers\n",
      "12\t0.639\tGlory Road\n",
      "\n",
      "george julie tim scott ed claire satan trevor doyle brad\n",
      "\n",
      "13\t0.924\tThe Kid\n",
      "13\t0.785\tSwing Vote\n",
      "13\t0.496\tTomboy\n",
      "13\t0.477\tKuffs\n",
      "13\t0.394\tDinner For Schmucks\n",
      "\n",
      "’ s bobby lucy rose marcus white wolf “ ”\n",
      "\n",
      "14\t0.741\tBlack House\n",
      "14\t0.721\tMy Life In Ruins\n",
      "14\t0.641\tWinnie the Pooh\n",
      "14\t0.636\tWhite Fang 2: Myth of the White Wolf\n",
      "14\t0.595\tNine\n",
      "\n",
      "john arthur daniel train grant crew julia howard clark vince\n",
      "\n",
      "15\t0.803\tSource Code\n",
      "15\t0.636\tDefending Your Life\n",
      "15\t0.479\tThe Karate Kid, Part III\n",
      "15\t0.476\tInception\n",
      "15\t0.410\tIron Man 2\n",
      "\n",
      "smith susan elliot dan sonny bishop leon natalie lana mac\n",
      "\n",
      "16\t0.671\tJerky Boys: The Movie\n",
      "16\t0.546\tAssault on Precinct 13\n",
      "16\t0.419\tCharlie's Angels\n",
      "16\t0.360\tBeyond the Valley of the Dolls\n",
      "16\t0.321\tBoys Don't Cry\n",
      "\n",
      "jesse rachel cole barry eric jessie travis logan sheriff mark\n",
      "\n",
      "17\t0.637\tThe Rage: Carrie 2\n",
      "17\t0.565\tThe Rundown\n",
      "17\t0.562\tThe Lucky One\n",
      "17\t0.333\tAppaloosa\n",
      "17\t0.286\tVenus\n",
      "\n",
      "king will kill escape find queen himself fight can '\n",
      "\n",
      "18\t0.981\tThe Lord of the Rings: The Two Towers\n",
      "18\t0.917\tThe Lord of the Rings: The Return of the King\n",
      "18\t0.871\tKrull\n",
      "18\t0.864\tThe Lord of the Rings: The Fellowship of the Ring\n",
      "18\t0.816\tThe Lord of the Rings\n",
      "\n",
      "harry doc marty penny ron sally keith | hector troy\n",
      "\n",
      "19\t0.445\tBack to the Future\n",
      "19\t0.382\tBack to the Future Part II\n",
      "19\t0.305\tBack to the Future Part III\n",
      "19\t0.299\tHarry Potter and the Deathly Hallows – Part 2\n",
      "19\t0.296\tThe Cat in the Hat\n",
      "\n",
      "max mr. ted ned louis mrs. wayne jenny egg lola\n",
      "\n",
      "20\t0.679\tBarney's Great Adventure\n",
      "20\t0.622\tMr. Magoo\n",
      "20\t0.500\tWayne's World 2\n",
      "20\t0.497\tThe Secret of NIMH\n",
      "20\t0.473\tThe Adventures of Sharkboy and Lavagirl\n",
      "\n",
      "martin andy alice barbara ethan liz plane stanley virus flight\n",
      "\n",
      "21\t0.565\tHow to Eat Fried Worms\n",
      "21\t0.450\tToy Story\n",
      "21\t0.415\tResident Evil: Extinction\n",
      "21\t0.407\tResident Evil: Retribution\n",
      "21\t0.371\tMission: Impossible III\n",
      "\n",
      "paul lisa sean kim charles wyatt gilbert clara betty murphy\n",
      "\n",
      "22\t0.877\tVoice of a Murderer\n",
      "22\t0.714\tStriptease\n",
      "22\t0.607\tReservoir Dogs\n",
      "22\t0.605\tJust Cause\n",
      "22\t0.519\tMurphy's Law\n",
      "\n",
      "frank money ben kevin get family car all home jimmy\n",
      "\n",
      "23\t0.952\tThings Are Tough All Over\n",
      "23\t0.880\tLottery Ticket\n",
      "23\t0.839\tDisorderlies\n",
      "23\t0.764\tCatch Me If You Can\n",
      "23\t0.764\tThe Honeymooners\n",
      "\n",
      "alex christine greg dragon love harold charlotte penguins carrie phantom\n",
      "\n",
      "24\t0.797\tShrek 2\n",
      "24\t0.590\tMadagascar 3: Europe's Most Wanted\n",
      "24\t0.536\tBedknobs and Broomsticks\n",
      "24\t0.491\tMr. Popper's Penguins\n",
      "24\t0.365\tMadagascar\n",
      "\n",
      "david jason tommy jill molly steven miller freddy luke dale\n",
      "\n",
      "25\t0.548\tFreddy vs. Jason\n",
      "25\t0.414\tFriday the 13th Part VI: Jason Lives\n",
      "25\t0.328\tGone\n",
      "25\t0.312\tFriday the 13th\n",
      "25\t0.293\tStar Wars Episode VI: Return of the Jedi\n",
      "\n",
      "terry phil tyler fred rocky jeff doug chuck alan victor\n",
      "\n",
      "26\t0.396\tThe River Wild\n",
      "26\t0.319\tHighlander\n",
      "26\t0.264\tFight Club\n",
      "26\t0.254\tRemember Me\n",
      "26\t0.242\tThe Hills Have Eyes\n",
      "\n",
      "film mother father life had family man young this will\n",
      "\n",
      "27\t0.982\tThe Last Station\n",
      "27\t0.952\tLove in the Time of Cholera\n",
      "27\t0.944\tWhispers in the Dark\n",
      "27\t0.918\tOn Golden Pond\n",
      "27\t0.908\tThe Honorary Consul\n",
      "\n",
      "ship earth planet robot alien duke joey space } crew\n",
      "\n",
      "28\t0.961\tStar Trek: The Motion Picture\n",
      "28\t0.740\tStar Trek Nemesis\n",
      "28\t0.658\tStar Trek V: The Final Frontier\n",
      "28\t0.636\tStar Trek II: The Wrath of Khan\n",
      "28\t0.632\tThe Iron Giant\n",
      "\n",
      "dave annie jim helen grace martha meg pete margaret jackson\n",
      "\n",
      "29\t0.622\tMuppet Treasure Island\n",
      "29\t0.237\tHush\n",
      "29\t0.213\tThe Hitcher\n",
      "29\t0.207\tBridesmaids\n",
      "29\t0.194\tTreasure Planet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_model=lda_model \n",
    "\n",
    "topic_docs=[]\n",
    "for i in range(num_topics):\n",
    "    topic_docs.append({})\n",
    "for doc_id in range(len(corpus)):\n",
    "    doc_topics=topic_model.get_document_topics(corpus[doc_id])\n",
    "    for topic_num, topic_prob in doc_topics:\n",
    "        topic_docs[topic_num][doc_id]=topic_prob\n",
    "\n",
    "for i in range(num_topics):\n",
    "    print(\"%s\\n\" % ' '.join([term for term, freq in topic_model.show_topic(i, topn=10)]))\n",
    "    sorted_x = sorted(topic_docs[i].items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for k, v in sorted_x[:5]:\n",
    "        print(\"%s\\t%.3f\\t%s\" % (i,v,doc_names[k]))\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
