{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the use of the permutation test to assess the significance of coefficents learned in logistic regression (testing against the null that each $\\beta$ = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from random import choices\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            cols=line.rstrip().split(\"\\t\")\n",
    "            label=cols[0]\n",
    "            text=cols[1]\n",
    "            # assumes text is already tokenized\n",
    "            X.append(text)\n",
    "            Y.append(label)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change this to the directory with your data (from the CheckData_TODO.ipynb exercise).  \n",
    "# The directory should contain train.tsv, dev.tsv and test.tsv\n",
    "directory=\"../data/lmrd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainX, trainY=read_data(\"%s/train.tsv\" % directory)\n",
    "devX, devY=read_data(\"%s/dev.tsv\" % directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def featurize(trainX, devX):\n",
    "    vectorizer = CountVectorizer(max_features=10000, analyzer=str.split, lowercase=False, strip_accents=None, binary=True)\n",
    "\n",
    "    X_train = vectorizer.fit_transform(trainX)\n",
    "    X_dev = vectorizer.transform(devX)\n",
    "\n",
    "    return X_train, X_dev, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(X_train, trainY, le):\n",
    "    Y_train=le.transform(trainY)\n",
    "    logreg = linear_model.LogisticRegression(C=100, solver='lbfgs', penalty='l2', max_iter=10000)\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    return logreg\n",
    "    return logreg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(logreg, devX_feat, devY, le):\n",
    "    Y_dev=le.transform(devY)\n",
    "    print(\"Accuracy: %.3f\" % logreg.score(devX_feat, Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_weights(coefs, label_encoder, vocab, p_values):\n",
    "    reverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "    sort_index = np.argsort(coefs)\n",
    "\n",
    "    print(label_encoder.inverse_transform([0])[0])\n",
    "    for k in sort_index[:25]:\n",
    "        print (\"%.5f\\t%s\\t%.4f\" % (coefs[k], reverse_vocab[k], p_values[k] ))\n",
    "\n",
    "    print(label_encoder.inverse_transform([1])[0])\n",
    "\n",
    "    for k in reversed(sort_index[-25:]):\n",
    "        print (\"%.5f\\t%s\\t%.4f\" % (coefs[k], reverse_vocab[k], p_values[k] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.863\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "X_train, X_dev, vectorizer=featurize(trainX, devX)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(trainY)\n",
    "\n",
    "logreg=train(X_train, trainY, le)\n",
    "test(logreg, X_dev, devY, le)\n",
    "\n",
    "true_coefficients=logreg.coef_[0]\n",
    "\n",
    "# We'll set P=100 here to finish running in class, but set higher (e.g., 10000) for real applications\n",
    "P=100\n",
    "\n",
    "p_values=np.zeros(len(true_coefficients))\n",
    "permutedY=copy.deepcopy(trainY)\n",
    "\n",
    "for i in range(P):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    # permute the values of Y so that they're now attached to random data points in X\n",
    "    shuffle(permutedY)\n",
    "    \n",
    "    # train logistic regression on that permuted dataset\n",
    "    permuted_logreg=train(X_train, permutedY, le)\n",
    "    coefficients=permuted_logreg.coef_[0]\n",
    "    \n",
    "    # test how often the coefficients learned from the permuted data are as extreme as\n",
    "    # the coefficients from the true data\n",
    "    for idx, coef in enumerate(coefficients):\n",
    "        if abs(true_coefficients[idx]) < abs(coef):\n",
    "            p_values[idx]+=1./P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inverse_vocab = {v: k for k, v in vectorizer.vocabulary_.items()}            \n",
    "out=open(\"weights.txt\", \"w\")\n",
    "for idx, coef in enumerate(true_coefficients):\n",
    "    out.write(\"%.3f\\t%s\\t%.5f\\n\" % (coef, inverse_vocab[idx], p_values[idx]))\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "-6.76251\tremainder\t0.0300\n",
      "-6.55355\trequest\t0.0000\n",
      "-5.96585\tquorum\t0.0400\n",
      "-5.48654\tconstitutional\t0.1000\n",
      "-5.27949\tplease\t0.0300\n",
      "-5.24354\trohrabacher\t0.0800\n",
      "-5.14597\tobjection\t0.0100\n",
      "-5.01229\tbriefly\t0.0400\n",
      "-4.92054\twish\t0.0100\n",
      "-4.81034\tpresent\t0.0000\n",
      "-4.76935\tentitled\t0.0900\n",
      "-4.62166\tcovers\t0.1600\n",
      "-4.59619\ttwo\t0.0500\n",
      "-4.39108\tleader\t0.0200\n",
      "-4.38605\tmichigan\t0.1300\n",
      "-4.27747\tanswering\t0.2200\n",
      "-4.22751\tpermission\t0.0200\n",
      "-4.09117\treserved\t0.2800\n",
      "-4.07308\talthough\t0.2100\n",
      "-4.06503\t--\t0.1100\n",
      "-4.00915\toffer\t0.0400\n",
      "-3.94305\tsir\t0.2400\n",
      "-3.86242\tlooks\t0.2200\n",
      "-3.84841\toccurred\t0.1400\n",
      "-3.80051\tclerk\t0.1700\n",
      "R\n",
      "8.55687\trefuse\t0.0000\n",
      "6.96132\tfive\t0.0000\n",
      "6.17567\tscience\t0.0200\n",
      "6.13398\trespond\t0.0100\n",
      "5.67848\tleft\t0.0100\n",
      "5.65184\tconfident\t0.0700\n",
      "5.61088\trhetorical\t0.0500\n",
      "5.58951\ttable\t0.0900\n",
      "5.08841\thelping\t0.0100\n",
      "5.07008\tjudiciary\t0.1100\n",
      "4.97629\tdetained\t0.0300\n",
      "4.75859\twhose\t0.0600\n",
      "4.61480\tintent\t0.0500\n",
      "4.35216\tprepared\t0.1100\n",
      "4.28200\tresponse\t0.0500\n",
      "4.27023\t..\t0.2000\n",
      "4.22933\tasked\t0.0900\n",
      "4.11005\trose\t0.2400\n",
      "4.09022\texcept\t0.0300\n",
      "4.07792\ttuesday\t0.0600\n",
      "4.01051\torder\t0.0000\n",
      "4.00248\tturn\t0.0400\n",
      "3.97099\tbrief\t0.2100\n",
      "3.96067\tunderstanding\t0.0600\n",
      "3.89005\tground\t0.1600\n"
     ]
    }
   ],
   "source": [
    "analyze_weights(true_coefficients, le, vectorizer.vocabulary_, p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
