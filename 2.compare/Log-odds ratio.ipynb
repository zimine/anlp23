{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log-odds ratio with an informative (and uninformative) Dirichlet prior (described in [Monroe et al. 2009, Fighting Words](http://languagelog.ldc.upenn.edu/myl/Monroe.pdf)) is a common method for finding distinctive terms in two datasets (see [Jurafsky et al. 2014](https://firstmonday.org/ojs/index.php/fm/article/view/4944/3863) for an example article that uses it to make an empirical argument). This method for finding distinguishing words combines a number of desirable properties:\n",
    "\n",
    "* it specifies an intuitive metric (the log-odds) for the ratio of two probabilities\n",
    "* it can incorporate prior information in the form of pseudocounts, which can either act as a smoothing factor (in the uninformative case) or incorporate real information about the expected frequency of words overall.\n",
    "* it accounts for variability of a frequency estimate by essentially converting the log-odds to a z-score.\n",
    "\n",
    "In this homework you will implement this ratio for a dataset of your choice to characterize the words that differentiate each one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Your first job is to find two datasets with some interesting opposition -- e.g., news articles from CNN vs. FoxNews, books written by Charles Dickens vs. James Joyce, screenplays of dramas vs. comedies.  Be creative -- this should be driven by what interests you and should reflect your own originality. **This dataset cannot come from Kaggle**.  Feel feel to use web scraping (see [here](https://github.com/CU-ITSS/Web-Data-Scraping-S2023) for a great tutorial) or manually copying/pasting text.  Aim for more than 10,000 tokens for each dataset. \n",
    "   \n",
    "Save those datasets in two files: \"class1_dataset.txt\" and \"class2_dataset.txt\" \n",
    "\n",
    "Describe each of those datasets and their source in 100-200 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Tokenize those texts by filling out the `read_and_tokenize` function below (your choice of tokenizer). The input is a filename and the output should be a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, operator, math, nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_tokenize(filename):\n",
    "    \n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        tokens=[]\n",
    "        # lowercase\n",
    "        for line in file:\n",
    "            data=line.rstrip().lower()\n",
    "            # This dataset is already tokenized, so we can split on whitespace\n",
    "            tokens.extend(data.split(\" \"))\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_tokens=read_and_tokenize(\"../data/negative.reviews.txt\")\n",
    "class2_tokens=read_and_tokenize(\"../data/positive.reviews.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.  Now let's find the words that characterize each of those sources (with respect to the other). Implement the log-odds ratio with an uninformative Dirichlet prior.  This value, $\\hat\\zeta_w^{(i-j)}$ for word $w$ reflecting the difference in usage between corpus $i$ and corpus $j$, is given by the following equation:\n",
    "\n",
    "$$\n",
    "\\hat\\zeta_w^{(i-j)}= {\\hat{d}_w^{(i-j)} \\over \\sqrt{\\sigma^2\\left(\\hat{d}_w^{(i-j)}\\right)}}\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "$$\n",
    "\\hat{d}_w^{(i-j)} = \\log \\left({y_w^i + \\alpha_w} \\over {n^i + \\alpha_0 - y_w^i - \\alpha_w}) \\right) -  \\log \\left({y_w^j + \\alpha_w} \\over {n^j + \\alpha_0 - y_w^j - \\alpha_w}) \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma^2\\left(\\hat{d}_w^{(i-j)}\\right) \\approx {1 \\over {y_w^i + \\alpha_w}} + {1 \\over {y_w^j + \\alpha_w} }\n",
    "$$\n",
    "\n",
    "And:\n",
    "\n",
    "* $y_w^i = $ count of word $w$ in corpus $i$ (likewise for $j$)\n",
    "* $\\alpha_w$ = 0.01\n",
    "* $V$ = size of vocabulary (number of distinct word types)\n",
    "* $\\alpha_0 = V * \\alpha_w$\n",
    "* $n^i = $ number of words in corpus $i$ (likewise for $j$)\n",
    "\n",
    "Here the two corpora are the positive movie reviews (e.g., $i$ = positive) and the negative movie reviews (e.g., $j$ = negative). Using this metric, print out the 25 words most strongly aligned with the positive corpus, and 25 words most strongly aligned with the negative corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logodds_with_uninformative_prior(one_tokens, two_tokens, display=25):\n",
    "    \n",
    "    def get_counter_from_list(tokens):\n",
    "        counter=Counter()\n",
    "        for token in tokens:\n",
    "            counter[token]+=1\n",
    "        return counter\n",
    "\n",
    "\n",
    "    oneCounter=get_counter_from_list(one_tokens)\n",
    "    twoCounter=get_counter_from_list(two_tokens)\n",
    "    \n",
    "    vocab=dict(oneCounter) \n",
    "    vocab.update(dict(twoCounter))\n",
    "    oneSum=sum(oneCounter.values())\n",
    "    twoSum=sum(twoCounter.values())\n",
    "\n",
    "    ranks={}\n",
    "    alpha=0.01\n",
    "    alphaV=len(vocab)*alpha\n",
    "        \n",
    "    for word in vocab:\n",
    "        \n",
    "        log_odds_ratio=math.log( (oneCounter[word] + alpha) / (oneSum+alphaV-oneCounter[word]-alpha) ) - math.log( (twoCounter[word] + alpha) / (twoSum+alphaV-twoCounter[word]-alpha) )\n",
    "        variance=1./(oneCounter[word] + alpha) + 1./(twoCounter[word] + alpha)\n",
    "        \n",
    "        ranks[word]=log_odds_ratio/math.sqrt(variance)\n",
    "\n",
    "    sorted_x = sorted(ranks.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    print(\"Most positive:\")\n",
    "    for k,v in sorted_x[:display]:\n",
    "        print(\"%.3f\\t%s\" % (v,k))\n",
    "    \n",
    "    print(\"\\nMost negative:\")\n",
    "    for k,v in reversed(sorted_x[-display:]):\n",
    "        print(\"%.3f\\t%s\" % (v,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positive:\n",
      "15.874\tbad\n",
      "15.035\t?\n",
      "11.949\tn't\n",
      "10.960\tmovie\n",
      "9.929\tworst\n",
      "9.448\ti\n",
      "9.122\tjust\n",
      "8.676\t...\n",
      "8.618\twas\n",
      "7.999\tno\n",
      "7.521\tdo\n",
      "7.512\tawful\n",
      "7.446\tterrible\n",
      "7.373\tthey\n",
      "7.053\thorrible\n",
      "7.020\twhy\n",
      "6.935\tthis\n",
      "6.931\tpoor\n",
      "6.709\tboring\n",
      "6.685\tany\n",
      "6.674\twaste\n",
      "6.661\tscript\n",
      "6.601\tworse\n",
      "6.552\thave\n",
      "6.475\tstupid\n",
      "\n",
      "Most negative:\n",
      "-9.608\tgreat\n",
      "-8.445\this\n",
      "-8.221\tbest\n",
      "-8.068\tas\n",
      "-8.008\tand\n",
      "-7.466\tlove\n",
      "-7.232\twar\n",
      "-7.143\texcellent\n",
      "-6.697\twonderful\n",
      "-6.559\tis\n",
      "-6.389\ther\n",
      "-6.052\tperformance\n",
      "-5.937\t,\n",
      "-5.769\tof\n",
      "-5.722\tlife\n",
      "-5.707\thighly\n",
      "-5.664\tworld\n",
      "-5.547\tperfect\n",
      "-5.490\tin\n",
      "-5.466\talways\n",
      "-5.380\tperformances\n",
      "-5.356\tbeautiful\n",
      "-5.198\tmost\n",
      "-5.148\ttony\n",
      "-5.092\tloved\n"
     ]
    }
   ],
   "source": [
    "logodds_with_uninformative_prior(class1_tokens, class2_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
