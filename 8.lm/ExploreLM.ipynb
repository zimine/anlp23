{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b52b3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "from collections import Counter\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33eb376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    sequences=[]\n",
    "    with open(filename) as file:\n",
    "        data=file.read()\n",
    "        sents=sent_tokenize(data)\n",
    "        for sent in sents:\n",
    "            tokens=word_tokenize(sent)\n",
    "            sequences.append(tokens)\n",
    "            \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feeb46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file and tokenize them into sequences comprised of tokens.\n",
    "\n",
    "# 2020 Democratic Party platform\n",
    "# sequences=read_file(\"../data/democrat_platform_2020.txt\")\n",
    "\n",
    "# 2020 Republican Party platform\n",
    "# sequences=read_file(\"../data/republican_platform_2020.txt\")\n",
    "\n",
    "# Pride and Prejudice (Jane Austen)\n",
    "sequences=read_file(\"../data/stylometry/1342_pride_and_prejudice.txt\")\n",
    "\n",
    "# All of Shakespeare's plays\n",
    "# sequences=read_file(\"../data/pg100_plays.txt\")\n",
    "\n",
    "max_sequences=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "214dbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramModel():\n",
    "\n",
    "    def __init__(self, sequences, order):\n",
    "        \n",
    "        # For this exercise we're going to encode the LM as a sparse dictionary (training less storage for more compute)\n",
    "        # We'll store the LM as a dictionary with the conditioning context as keys; each value is a \n",
    "        # Counter object that keeps track of the number of times we see a word following that context.\n",
    "        \n",
    "        self.counts={}\n",
    "        \n",
    "        # Markov order (order 1 = conditioning on previous 1 word; order 2 = previous 2 words, etc.)\n",
    "        self.order=order\n",
    "        \n",
    "        vocab={\"[END]\":0}\n",
    "                \n",
    "        for s_idx, tokens in enumerate(sequences):\n",
    "            # We'll add [START] and [END] tokens to encode the beginning/end of sentences\n",
    "            token_copy=copy.deepcopy(tokens)\n",
    "            for i in range(order):\n",
    "                token_copy.insert(0, \"[START]\")\n",
    "            token_copy.append(\"[END]\")\n",
    "            \n",
    "        \n",
    "            for i in range(order, len(token_copy)):\n",
    "                context=\" \".join(token_copy[i-order:i])\n",
    "                word=token_copy[i]\n",
    "                \n",
    "                if word not in vocab:\n",
    "                    vocab[word]=len(vocab)\n",
    "                \n",
    "                # For just the first sentence, print the conditioning context + word\n",
    "                if s_idx == 0:\n",
    "                    print(\"Context: %s Next: %s\" % (context.ljust(50), word))\n",
    "                    \n",
    "                if context not in self.counts:\n",
    "                    self.counts[context]=Counter()\n",
    "                self.counts[context][word]+=1\n",
    "                \n",
    "\n",
    "\n",
    "    def sample(self, context):\n",
    "\n",
    "        total=sum(self.counts[context].values())\n",
    "        \n",
    "        dist=[]\n",
    "        vocab=[]\n",
    "\n",
    "        # Create a probability distribution for each conditioning context, over the vocab that we've observed it with.\n",
    "        for idx, word in enumerate(self.counts[context]):\n",
    "            prob=self.counts[context][word]/total\n",
    "            dist.append(prob)\n",
    "            vocab.append(word)\n",
    "\n",
    "        index=np.argmax(np.random.multinomial(1, pvals=dist))\n",
    "        #return vocab[index]\n",
    "        return vocab, dist\n",
    "        \n",
    "    def generate_sequence(self):\n",
    "        generated=[\"[START]\"]*(self.order)\n",
    "        word=None\n",
    "        while word != \"[END]\":\n",
    "            context=' '.join(generated[-self.order:] if self.order > 0 else \"\")\n",
    "            word=self.sample(context)\n",
    "            print(word)\n",
    "            generated.append(word)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a51b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [START]                                            Next: Chapter\n",
      "Context: Chapter                                            Next: 1\n",
      "Context: 1                                                  Next: It\n",
      "Context: It                                                 Next: is\n",
      "Context: is                                                 Next: a\n",
      "Context: a                                                  Next: truth\n",
      "Context: truth                                              Next: universally\n",
      "Context: universally                                        Next: acknowledged\n",
      "Context: acknowledged                                       Next: ,\n",
      "Context: ,                                                  Next: that\n",
      "Context: that                                               Next: a\n",
      "Context: a                                                  Next: single\n",
      "Context: single                                             Next: man\n",
      "Context: man                                                Next: in\n",
      "Context: in                                                 Next: possession\n",
      "Context: possession                                         Next: of\n",
      "Context: of                                                 Next: a\n",
      "Context: a                                                  Next: good\n",
      "Context: good                                               Next: fortune\n",
      "Context: fortune                                            Next: ,\n",
      "Context: ,                                                  Next: must\n",
      "Context: must                                               Next: be\n",
      "Context: be                                                 Next: in\n",
      "Context: in                                                 Next: want\n",
      "Context: want                                               Next: of\n",
      "Context: of                                                 Next: a\n",
      "Context: a                                                  Next: wife\n",
      "Context: wife                                               Next: .\n",
      "Context: .                                                  Next: [END]\n"
     ]
    }
   ],
   "source": [
    "ngram1=NgramModel(sequences[:max_sequences], order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79935c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since\n",
      "writing\n",
      ".\n",
      "[END]\n"
     ]
    }
   ],
   "source": [
    "ngram1.generate_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad8a2c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:                                                    Next: Chapter\n",
      "Context:                                                    Next: 1\n",
      "Context:                                                    Next: It\n",
      "Context:                                                    Next: is\n",
      "Context:                                                    Next: a\n",
      "Context:                                                    Next: truth\n",
      "Context:                                                    Next: universally\n",
      "Context:                                                    Next: acknowledged\n",
      "Context:                                                    Next: ,\n",
      "Context:                                                    Next: that\n",
      "Context:                                                    Next: a\n",
      "Context:                                                    Next: single\n",
      "Context:                                                    Next: man\n",
      "Context:                                                    Next: in\n",
      "Context:                                                    Next: possession\n",
      "Context:                                                    Next: of\n",
      "Context:                                                    Next: a\n",
      "Context:                                                    Next: good\n",
      "Context:                                                    Next: fortune\n",
      "Context:                                                    Next: ,\n",
      "Context:                                                    Next: must\n",
      "Context:                                                    Next: be\n",
      "Context:                                                    Next: in\n",
      "Context:                                                    Next: want\n",
      "Context:                                                    Next: of\n",
      "Context:                                                    Next: a\n",
      "Context:                                                    Next: wife\n",
      "Context:                                                    Next: .\n",
      "Context:                                                    Next: [END]\n"
     ]
    }
   ],
   "source": [
    "ngram0=NgramModel(sequences[:max_sequences], order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6982433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her\n",
      "into\n",
      "to\n",
      "I\n",
      "must\n",
      ",\n",
      "“\n",
      "reputed\n",
      "be\n",
      "myself\n",
      "spirit\n",
      "instead\n",
      "wish\n",
      "after\n",
      "the\n",
      "eminent\n",
      "in\n",
      "good\n",
      "of\n",
      "the\n",
      "felt\n",
      "--\n",
      "will\n",
      "she\n",
      "well\n",
      "then\n",
      "encouragement\n",
      "I\n",
      "was\n",
      "what\n",
      "brother\n",
      "my\n",
      "what\n",
      ";\n",
      "now\n",
      "him\n",
      "promise\n",
      "interview\n",
      "bequeathed\n",
      "with\n",
      ";\n",
      "who\n",
      "immediately\n",
      "pay\n",
      "very\n",
      "affectionate\n",
      "lively\n",
      "is\n",
      "Mrs.\n",
      "really\n",
      ",\n",
      "Forster\n",
      "me\n",
      "injunction\n",
      "warmth\n",
      "went\n",
      "!\n",
      "she\n",
      "you\n",
      "marrying\n",
      "on\n",
      "but\n",
      "so.\n",
      "and\n",
      "high\n",
      "constant\n",
      "own\n",
      "by\n",
      "endeavoured\n",
      "disgusted\n",
      "--\n",
      "token\n",
      "Mrs.\n",
      "the\n",
      "and\n",
      ",\n",
      "A\n",
      "there\n",
      "because\n",
      "Darcy\n",
      "”\n",
      ",\n",
      "prodigiously.\n",
      "am\n",
      "same\n",
      "[END]\n"
     ]
    }
   ],
   "source": [
    "ngram0.generate_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35ee1ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [START] [START]                                    Next: Chapter\n",
      "Context: [START] Chapter                                    Next: 1\n",
      "Context: Chapter 1                                          Next: It\n",
      "Context: 1 It                                               Next: is\n",
      "Context: It is                                              Next: a\n",
      "Context: is a                                               Next: truth\n",
      "Context: a truth                                            Next: universally\n",
      "Context: truth universally                                  Next: acknowledged\n",
      "Context: universally acknowledged                           Next: ,\n",
      "Context: acknowledged ,                                     Next: that\n",
      "Context: , that                                             Next: a\n",
      "Context: that a                                             Next: single\n",
      "Context: a single                                           Next: man\n",
      "Context: single man                                         Next: in\n",
      "Context: man in                                             Next: possession\n",
      "Context: in possession                                      Next: of\n",
      "Context: possession of                                      Next: a\n",
      "Context: of a                                               Next: good\n",
      "Context: a good                                             Next: fortune\n",
      "Context: good fortune                                       Next: ,\n",
      "Context: fortune ,                                          Next: must\n",
      "Context: , must                                             Next: be\n",
      "Context: must be                                            Next: in\n",
      "Context: be in                                              Next: want\n",
      "Context: in want                                            Next: of\n",
      "Context: want of                                            Next: a\n",
      "Context: of a                                               Next: wife\n",
      "Context: a wife                                             Next: .\n",
      "Context: wife .                                             Next: [END]\n"
     ]
    }
   ],
   "source": [
    "ngram2=NgramModel(sequences[:max_sequences], order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24378b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "next\n",
      "variation\n",
      "which\n",
      "their\n",
      "visit\n",
      "to\n",
      "proceed\n",
      "from\n",
      "the\n",
      "object\n",
      "of\n",
      "her\n",
      "brother\n",
      ",\n",
      "though\n",
      "expecting\n",
      "no\n",
      "less\n",
      "certain\n",
      "is\n",
      "it\n",
      "you\n",
      "mean\n",
      "?\n",
      "”\n",
      "“\n",
      "How\n",
      "should\n",
      "you\n",
      "think\n",
      "him\n",
      "less\n",
      "agreeable\n",
      "man\n",
      "I\n",
      "know\n",
      ",\n",
      "that\n",
      "Elizabeth\n",
      "had\n",
      "been\n",
      "designed\n",
      "for\n",
      "him\n",
      ",\n",
      "except\n",
      "the\n",
      "professed\n",
      "lover\n",
      "of\n",
      "her\n",
      "intelligence\n",
      "was\n",
      "all\n",
      "grateful\n",
      "pleasure\n",
      ",\n",
      "unconnected\n",
      "with\n",
      "any\n",
      "complacency\n",
      ".\n",
      "[END]\n"
     ]
    }
   ],
   "source": [
    "ngram2.generate_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41c37841-12d0-4696-b1f2-3b3269599ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['are',\n",
       "  '.',\n",
       "  'quieted',\n",
       "  'was',\n",
       "  'herself',\n",
       "  ')',\n",
       "  'might',\n",
       "  ',',\n",
       "  'were',\n",
       "  'began',\n",
       "  'without',\n",
       "  'could',\n",
       "  'will',\n",
       "  'has',\n",
       "  'and'],\n",
       " [0.058823529411764705,\n",
       "  0.058823529411764705,\n",
       "  0.058823529411764705,\n",
       "  0.11764705882352941,\n",
       "  0.058823529411764705,\n",
       "  0.058823529411764705,\n",
       "  0.058823529411764705,\n",
       "  0.11764705882352941,\n",
       "  0.058823529411764705,\n",
       "  0.058823529411764705,\n",
       "  0.058823529411764705,\n",
       "  0.058823529411764705,\n",
       "  0.058823529411764705,\n",
       "  0.058823529411764705,\n",
       "  0.058823529411764705])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram2.sample(\"Lady Lucas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b912fc3-0978-4e65-a392-cd92e7ab6140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [START] [START] [START] [START] [START] [START] [START] [START] [START] [START] Next: Chapter\n",
      "Context: [START] [START] [START] [START] [START] [START] [START] [START] [START] Chapter Next: 1\n",
      "Context: [START] [START] [START] [START] [START] [START] [START] [START] Chapter 1 Next: It\n",
      "Context: [START] [START] [START] [START] [START] [START] [START] Chapter 1 It Next: is\n",
      "Context: [START] [START] [START] [START] [START] [START] Chapter 1 It is Next: a\n",
      "Context: [START] [START] [START] [START] [START] Chapter 1 It is a Next: truth\n",
      "Context: [START] [START] [START] [START] Chapter 1 It is a truth Next: universally\n",
      "Context: [START] [START] [START] Chapter 1 It is a truth universally Next: acknowledged\n",
      "Context: [START] [START] Chapter 1 It is a truth universally acknowledged Next: ,\n",
      "Context: [START] Chapter 1 It is a truth universally acknowledged , Next: that\n",
      "Context: Chapter 1 It is a truth universally acknowledged , that Next: a\n",
      "Context: 1 It is a truth universally acknowledged , that a  Next: single\n",
      "Context: It is a truth universally acknowledged , that a single Next: man\n",
      "Context: is a truth universally acknowledged , that a single man Next: in\n",
      "Context: a truth universally acknowledged , that a single man in Next: possession\n",
      "Context: truth universally acknowledged , that a single man in possession Next: of\n",
      "Context: universally acknowledged , that a single man in possession of Next: a\n",
      "Context: acknowledged , that a single man in possession of a Next: good\n",
      "Context: , that a single man in possession of a good        Next: fortune\n",
      "Context: that a single man in possession of a good fortune  Next: ,\n",
      "Context: a single man in possession of a good fortune ,     Next: must\n",
      "Context: single man in possession of a good fortune , must  Next: be\n",
      "Context: man in possession of a good fortune , must be      Next: in\n",
      "Context: in possession of a good fortune , must be in       Next: want\n",
      "Context: possession of a good fortune , must be in want     Next: of\n",
      "Context: of a good fortune , must be in want of             Next: a\n",
      "Context: a good fortune , must be in want of a              Next: wife\n",
      "Context: good fortune , must be in want of a wife           Next: .\n",
      "Context: fortune , must be in want of a wife .              Next: [END]\n"
     ]
    }
   ],
   "source": [
    "ngram3=NgramModel(sequences[:max_sequences], order=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3786edd4-6622-4081-b1ba-f262bed05960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At\n",
      "present\n",
      "I\n",
      "have\n",
      "not\n",
      "room\n",
      "to\n",
      "do\n",
      "them\n",
      "justice.\n",
      "”\n",
      "“\n",
      "Oh\n",
      "!\n",
      "[END]\n"
     ]
    }
   ],
   "source": [
    "ngram3.generate_sequence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0fe5d",
   "metadata": {},
   "source": [
    "A1. Explore sampling sequences from LMs of different orders above; what do you notice about the structure of the generated texts (and how they differ by orders)?  Explore LMs trained on different datasets as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d737d53-2c44-4534-b7dc-e32e7bdd89fb",
   "metadata": {},
   "source": [
    "Order 0 model generates single words based entirely own its relative frequency, without considering context at all. Order 1 and order 2 models generate words based on previous tokens. There is some semantic/syntactic structure preserved in the order 2 model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c57df0",
   "metadata": {},
   "source": [
    "A2. In a second-order LM estimated from `1342_pride_and_prejudice.txt` above, what's $P(\\textrm{are} | \\textrm{Lady Lucas})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df546e9-ac74-4060-aef1-40a9a5894302",
   "metadata": {},
   "source": [
    "The probability of `are` occuring after `Lady Lucas` is 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da32d0e0",
   "metadata": {},
   "source": [
    "A3. Keep increasing the order of LMs (well past 3); compare the text that's generated to the original dataset (in the files above); are the LMs simply memorizing the source material?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b0eda-4f20-4c63-a18a-35725269f6bb",
   "metadata": {},
   "source": [
    "For a small training sample like this, it seems that the generated outputs resemble the orginal text a lot. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
